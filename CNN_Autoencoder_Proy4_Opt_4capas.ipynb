{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6163,"status":"ok","timestamp":1639457453811,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"ehMbHQ9nXmuf"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transform\n","import torch.nn.functional as F\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24286,"status":"ok","timestamp":1639457478085,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"asyebzoxXmi_","outputId":"0ce49463-14a2-4ef0-e7ef-2bf4bed1015b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10331,"status":"ok","timestamp":1639457488405,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"kbl5_2KaE-vN","outputId":"361fb2d9-c98b-4e9d-87f1-ef3d55d8f5a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n","torch.Size([3, 256, 256])\n"]}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","batch_size = 64\n","\n","#img_transform = transform.Compose([transform.ToTensor(), transform.Normalize((0.5,),(0.5,))]) \n","\n","path = '/content/drive/MyDrive/ml-proyecto-4/'\n","#path = 'Dataset/'\n","\n","trainLow_set = torchvision.datasets.ImageFolder(root=path+'dataset_low/train', transform = transform.ToTensor())\n","trainHigh_set = torchvision.datasets.ImageFolder(root=path+'dataset_high/train', transform = transform.ToTensor())\n","\n","validLow_set = torchvision.datasets.ImageFolder(root=path+'dataset_low/valid', transform = transform.ToTensor())\n","validHigh_set = torchvision.datasets.ImageFolder(root=path+'dataset_high/valid', transform = transform.ToTensor())\n","\n","testLow_set = torchvision.datasets.ImageFolder(root=path+'dataset_low/test', transform = transform.ToTensor())\n","testHigh_set = torchvision.datasets.ImageFolder(root=path+'dataset_high/test', transform = transform.ToTensor())\n","\n","#trainLow_set = np.load(path+'train/low_res')\n","#train_loader = torch.utils.data.DataLoader(dataset=trainLow_set, batch_size=batch_size, shuffle=True)\n","\n","#img, _ = train_set[0]\n","img, _ = trainLow_set[0]\n","print(img.shape)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=trainLow_set, batch_size=batch_size, shuffle=False)\n","valid_loader = torch.utils.data.DataLoader(dataset=validLow_set, batch_size=batch_size, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(dataset=testLow_set, batch_size=batch_size, shuffle=False)\n","\n","\n","train_h_loader = torch.utils.data.DataLoader(dataset=trainHigh_set, batch_size=batch_size, shuffle=False)\n","valid_h_loader = torch.utils.data.DataLoader(dataset=validHigh_set, batch_size=batch_size, shuffle=False)\n","test_h_loader = torch.utils.data.DataLoader(dataset=testHigh_set, batch_size=batch_size, shuffle=False)\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":351,"status":"ok","timestamp":1639457492008,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"_vtvDpVjG8U8"},"outputs":[],"source":["# numero de capas (2 capas)\n","class Encoder(nn.Module):\n","  def __init__(self):\n","    super(Encoder, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1) #(256+2*1)= 258-4 =254 -\u003e 254/2+1 = 128\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1) #(128+2*1)= 130-4 =126 -\u003e 126/2+1 = 64\n","    self.fc = nn.Linear(in_features=128*64*64, out_features=256)\n","\n","  def forward(self, image):\n","    convs = []\n","    out = F.relu(self.conv1(image))\n","    convs.append(out)\n","    out = F.relu(self.conv2(out))\n","    convs.append(out)\n","    out = out.view(out.size(0), -1)\n","    z = self.fc(out)\n","    return z, convs\n","\n","class Decoder(nn.Module):\n","  def __init__(self):\n","    super(Decoder, self).__init__()\n","\n","    self.fc = nn.Linear(in_features=256,out_features=128*64*64) \n","    self.convTran1 = nn.ConvTranspose2d(in_channels=2*128,out_channels=64, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran2 = nn.ConvTranspose2d(in_channels=2*64,out_channels=3, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","   \n","  def forward(self, latent,params):\n","    out = self.fc(latent)\n","    out = out.view(out.size(0), 128, 64, 64)\n","\n","    out = torch.cat((params[1],out),1)\n","    out = torch.relu(self.convTran1(out))\n","    \n","    out = torch.cat((params[0],out),1)\n","    out = torch.tanh(self.convTran2(out))\n","\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaEOT9CRK36G"},"outputs":[],"source":["# 3 capas\n","class Encoder(nn.Module):\n","  def __init__(self):\n","    super(Encoder, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1) #(256+2*1)= 258-4 =254 -\u003e 254/2+1 = 128\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1) #(128+2*1)= 130-4 =126 -\u003e 126/2+1 = 64\n","    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1) #(64+2*1)= 66-4 =62 -\u003e 62/2+1 = 32\n","    #self.fc = nn.Linear(in_features=256*32*32, out_features=256)\n","    self.fc = nn.Linear(in_features=256*32*32, out_features=512)\n","\n","  def forward(self, image):\n","    convs = []\n","    out = F.relu(self.conv1(image))\n","    convs.append(out)\n","    out = F.relu(self.conv2(out))\n","    convs.append(out)\n","    out = F.relu(self.conv3(out))\n","    convs.append(out)\n","    out = out.view(out.size(0), -1)\n","    z = self.fc(out)\n","    return z, convs\n","\n","class Decoder(nn.Module):\n","  def __init__(self):\n","    super(Decoder, self).__init__()\n","\n","    self.fc = nn.Linear(in_features=512,out_features=256*32*32) \n","    #self.fc = nn.Linear(in_features=256,out_features=256*32*32) \n","    self.convTran1 = nn.ConvTranspose2d(in_channels=2*256,out_channels=128, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran2 = nn.ConvTranspose2d(in_channels=2*128,out_channels=64, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran3 = nn.ConvTranspose2d(in_channels=2*64,out_channels=3, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","   \n","  def forward(self, latent,params):\n","    out = self.fc(latent)\n","    #out = out.view(out.size(0), 256, 32, 32)\n","\n","    out = out.view(out.size(0), 256, 32, 32)\n","\n","    out = torch.cat((params[2],out),1)\n","    out = F.relu(self.convTran1(out))\n","\n","    out = torch.cat((params[1],out),1)\n","    out = torch.tanh(self.convTran2(out))\n","    \n","    out = torch.cat((params[0],out),1)\n","    out = torch.tanh(self.convTran3(out))\n","\n","    return out\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1639457500319,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"nU4uKJ-kLH9-"},"outputs":[],"source":["# 4 capas\n","class Encoder(nn.Module):\n","  def __init__(self):\n","    super(Encoder, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1) #(256+2*1)= 258-4 =254 -\u003e 254/2+1 = 128\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1) #(128+2*1)= 130-4 =126 -\u003e 126/2+1 = 64\n","    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1) #(64+2*1)= 66-4 =62 -\u003e 62/2+1 = 32\n","    self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1) #(64+2*1)= 66-4 =62 -\u003e 62/2+1 = 32    \n","    self.fc = nn.Linear(in_features=512*16*16, out_features=1024)\n","\n","  def forward(self, image):\n","    convs = []\n","    out = F.relu(self.conv1(image))\n","    convs.append(out)\n","    out = F.relu(self.conv2(out))\n","    convs.append(out)\n","    out = F.relu(self.conv3(out))\n","    convs.append(out)\n","    out = F.relu(self.conv4(out))\n","    convs.append(out)    \n","    out = out.view(out.size(0), -1)\n","    z = self.fc(out)\n","    return z, convs\n","\n","class Decoder(nn.Module):\n","  def __init__(self):\n","    super(Decoder, self).__init__()\n","\n","    self.fc = nn.Linear(in_features=1024,out_features=512*16*16) \n","    self.convTran1 = nn.ConvTranspose2d(in_channels=2*512,out_channels=256, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran2 = nn.ConvTranspose2d(in_channels=2*256,out_channels=128, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran3 = nn.ConvTranspose2d(in_channels=2*128,out_channels=64, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran4 = nn.ConvTranspose2d(in_channels=2*64,out_channels=3, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","   \n","  def forward(self, latent,params):\n","    out = self.fc(latent)\n","\n","    out = out.view(out.size(0), 512, 16, 16)\n","\n","    out = torch.cat((params[3],out),1)\n","    out = F.relu(self.convTran1(out))\n","\n","    out = torch.cat((params[2],out),1)\n","    out = F.relu(self.convTran2(out))\n","\n","    out = torch.cat((params[1],out),1)\n","    out = torch.tanh(self.convTran3(out))\n","    \n","    out = torch.cat((params[0],out),1)\n","    out = torch.tanh(self.convTran4(out))\n","\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AD3IU1UML9dX"},"outputs":[],"source":["# 4 capas con pooling ------------ ACA\n","class Encoder(nn.Module):\n","  def __init__(self):\n","    super(Encoder, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1) #(256+2*1)= 258-4 =254 -\u003e 254/2+1 = 128\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1) #(128+2*1)= 130-4 =126 -\u003e 126/2+1 = 64\n","    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1) #(64+2*1)= 66-4 =62 -\u003e 62/2+1 = 32\n","    self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1) #(64+2*1)= 66-4 =62 -\u003e 62/2+1 = 32    \n","    self.pool = nn.MaxPool2d(2,2)\n","    #self.fc = nn.Linear(in_features=512*16*16, out_features=1024)\n","    self.fc = nn.Linear(in_features=512*8*8, out_features=1024)\n","\n","  def forward(self, image):\n","    convs = []\n","    out = F.relu(self.conv1(image))\n","    convs.append(out)\n","    out = F.relu(self.conv2(out))\n","    convs.append(out)\n","    out = F.relu(self.conv3(out))\n","    convs.append(out)\n","    out = F.relu(self.conv4(out))\n","    out = self.pool(out)\n","    convs.append(out)    \n","    out = out.view(out.size(0), -1)\n","    z = self.fc(out)\n","    return z, convs\n","\n","class Decoder(nn.Module):\n","  def __init__(self):\n","    super(Decoder, self).__init__()\n","\n","    self.fc = nn.Linear(in_features=1024,out_features=512*8*8) \n","    self.convTran1 = nn.ConvTranspose2d(in_channels=2*512,out_channels=256, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran2 = nn.ConvTranspose2d(in_channels=2*256,out_channels=128, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran3 = nn.ConvTranspose2d(in_channels=2*128,out_channels=64, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran4 = nn.ConvTranspose2d(in_channels=2*64,out_channels=3, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","   \n","  def forward(self, latent,params):\n","    out = self.fc(latent)\n","\n","    out = out.view(out.size(0), 512, 16, 16)\n","\n","    out = torch.cat((params[3],out),1)\n","    out = F.relu(self.convTran1(out))\n","\n","    out = torch.cat((params[2],out),1)\n","    out = F.relu(self.convTran2(out))\n","\n","    out = torch.cat((params[1],out),1)\n","    out = torch.tanh(self.convTran3(out))\n","    \n","    out = torch.cat((params[0],out),1)\n","    out = torch.tanh(self.convTran4(out))\n","\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xx616fTKFK_n"},"outputs":[],"source":["# Modelo (pro)\n","class Encoder(nn.Module):\n","  def __init__(self):\n","    super(Encoder, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1) #(256+2*1)= 258-4 =254 -\u003e 254/2+1 = 128\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1) #(128+2*1)= 130-4 =126 -\u003e 126/2+1 = 64\n","    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1) #(64+2*1)= 66-4 =62 -\u003e 62/2+1 = 32\n","    self.fc = nn.Linear(in_features=256*32*32, out_features=512)\n","\n","  def forward(self, image):\n","    convs = []\n","    out = F.relu(self.conv1(image))\n","    convs.append(out)\n","    out = F.relu(self.conv2(out))\n","    convs.append(out)\n","    out = F.relu(self.conv3(out))\n","    convs.append(out)\n","    out = out.view(out.size(0), -1)\n","    z = self.fc(out)\n","    return z, convs\n","\n","class Decoder(nn.Module):\n","  def __init__(self):\n","    super(Decoder, self).__init__()\n","\n","    self.fc = nn.Linear(in_features=512,out_features=256*32*32) \n","    self.convTran1 = nn.ConvTranspose2d(in_channels=2*256,out_channels=128, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran2 = nn.ConvTranspose2d(in_channels=2*128,out_channels=64, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran3 = nn.ConvTranspose2d(in_channels=2*64,out_channels=3, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","   \n","  def forward(self, latent, params):\n","    out = self.fc(latent)\n","    out = out.view(out.size(0), 256, 32, 32)\n","\n","    out = torch.cat((params[2],out),1)\n","    out = F.relu(self.convTran1(out))\n","\n","    out = torch.cat((params[1],out),1)\n","    out = torch.tanh(self.convTran2(out))\n","    \n","    out = torch.cat((params[0],out),1)\n","    out = torch.tanh(self.convTran3(out))\n","\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dOvz_OFNEXn0"},"outputs":[],"source":["# Modificacion de tamanho de kernel\n","class Encoder(nn.Module):\n","  def __init__(self):\n","    super(Encoder, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=6, stride=3, padding=1) #(256+2*1)= 258 - 6 = 253 -\u003e 253/2 + 1 = 85\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=6, stride=3, padding=1) #(127+2*1)= 127 - 5 = 122 -\u003e 122/2 + 1 = 28\n","    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=6, stride=3, padding=1) #(63+2*1)= 63 - 5 = 58 -\u003e 58/2 + 1 = 9\n","    self.fc = nn.Linear(in_features=256*9*9, out_features=512)\n","\n","  def forward(self, image):\n","    print(\"---encoder@forward\")\n","    convs = []\n","    out = F.relu(self.conv1(image))\n","    print(\"---encoder@forward-0\")\n","    print(out.shape)\n","    convs.append(out)\n","    out = F.relu(self.conv2(out))\n","    print(\"---encoder@forward-1\")\n","    print(out.shape)\n","    convs.append(out)\n","    out = F.relu(self.conv3(out))\n","    print(\"---encoder@forward-2\")\n","    print(out.shape)\n","    convs.append(out)\n","    out = out.view(out.size(0), -1)\n","    print(\"---encoder@forward-view\")\n","    print(out.shape)\n","    z = self.fc(out)\n","    print(\"---encoder@forward-latent\")\n","    print(z.shape)\n","    return z, convs\n","\n","class Decoder(nn.Module):\n","  def __init__(self):\n","    super(Decoder, self).__init__()\n","\n","    self.fc = nn.Linear(in_features=512, out_features=256*9*9)\n","    self.convTran1 = nn.ConvTranspose2d(in_channels=2*256,out_channels=128, kernel_size=6, stride=3, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran2 = nn.ConvTranspose2d(in_channels=2*128,out_channels=64, kernel_size=6, stride=3, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran3 = nn.ConvTranspose2d(in_channels=2*64,out_channels=3, kernel_size=6, stride=3, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","   \n","  def forward(self, latent,params):\n","    print(\"---decoder@forward\")\n","    out = self.fc(latent)\n","    print(\"---decoder@forward-latent\")\n","    print(out.shape)\n","\n","    out = out.view(out.size(0), 256, 9, 9)\n","    print(\"---decoder@forward-view\")\n","    print(out.shape)\n","\n","    out = torch.cat((params[2],out),1)\n","    print(\"---decoder@forward-2\")\n","    print(out.shape)\n","    out = F.relu(self.convTran1(out))\n","\n","    out = torch.cat((params[1],out),1)\n","    print(\"---decoder@forward-1\")\n","    print(out.shape)\n","    out = torch.tanh(self.convTran2(out))\n","    \n","    out = torch.cat((params[0], out), 1)\n","    print(\"---decoder@forward-0\")\n","    print(out.shape)\n","    out = torch.tanh(self.convTran3(out))\n","\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PLrmlBMGtmb"},"outputs":[],"source":["# Relus -tanh\n","class Encoder(nn.Module):\n","  def __init__(self):\n","    super(Encoder, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1) #(256+2*1)= 258-4 =254 -\u003e 254/2+1 = 128\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1) #(128+2*1)= 130-4 =126 -\u003e 126/2+1 = 64\n","    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1) #(64+2*1)= 66-4 =62 -\u003e 62/2+1 = 32\n","    #self.fc = nn.Linear(in_features=256*32*32, out_features=256)\n","    self.fc = nn.Linear(in_features=256*32*32, out_features=512)\n","\n","  def forward(self, image):\n","    convs = []\n","    out = F.tanh(self.conv1(image))\n","    convs.append(out)\n","    out = F.tanh(self.conv2(out))\n","    convs.append(out)\n","    out = F.tanh(self.conv3(out))\n","\n","    convs.append(out)\n","    out = out.view(out.size(0), -1)\n","    z = self.fc(out)\n","    return z, convs\n","\n","class Decoder(nn.Module):\n","  def __init__(self):\n","    super(Decoder, self).__init__()\n","\n","    self.fc = nn.Linear(in_features=512,out_features=256*32*32) \n","    self.convTran1 = nn.ConvTranspose2d(in_channels=2*256,out_channels=128, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran2 = nn.ConvTranspose2d(in_channels=2*128,out_channels=64, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","    self.convTran3 = nn.ConvTranspose2d(in_channels=2*64,out_channels=3, kernel_size=4, stride=2, padding=1) #Modificando inchannels. x2 por la copia U-Net\n","   \n","  def forward(self, latent,params):\n","    out = self.fc(latent)\n","    out = out.view(out.size(0), 256, 32, 32)\n","\n","    out = torch.cat((params[2],out),1)\n","    out = F.tanh(self.convTran1(out))\n","\n","    out = torch.cat((params[1],out),1)\n","    out = torch.tanh(self.convTran2(out))\n","    \n","    out = torch.cat((params[0],out),1)\n","    out = torch.tanh(self.convTran3(out))\n","\n","    return out\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1639457511537,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"eQ5-elKGvayj"},"outputs":[],"source":["class Autoencoder(nn.Module):\n","   def __init__(self):\n","        super(Autoencoder, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","\n","   def forward(self, x):\n","        latent, convs = self.encoder(x)\n","        x_recon = self.decoder(latent,convs)\n","        return  x_recon"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":337,"status":"ok","timestamp":1639457514394,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"3gfxVuePHEW2"},"outputs":[],"source":["def train(model, train_loader, Epochs, loss_fn, train_h_loader, valid_loader, valid_h_loader):\n","    train_loss_avg = []\n","    valid_loss_avg=[]\n","    for epoch in range(Epochs):\n","      #train_loss_avg.append(0)\n","      #num_batches = 0\n","      \n","      # --------------------------------------------- #\n","      # Error sobre el conjunto de validacion\n","      iterValidLoader = iter(valid_loader)\n","      iterValidHighLoader = iter(valid_h_loader)\n","      \n","      lossValidList = list()\n","      for yy in range(len(iterValidLoader)):\n","        imageVal_batch, _ = next(iterValidLoader)\n","        imageVal_batch = imageVal_batch.to(device)\n","        predValid = model(imageVal_batch)\n","          \n","        imageVal_h_batch, _ = next(iterValidHighLoader)\n","        imageVal_h_batch = imageVal_h_batch.to(device)\n","          \n","        lossValid = loss_fn(predValid, imageVal_h_batch)\n","        lossValidList.append(lossValid.item())\n","\n","      errValidMean = np.mean(lossValidList)\n","      valid_loss_avg.append(errValidMean) \n","      \n","      # --------------------------------------------- #\n","      \n","      #for image_batch, _ in train_loader:\n","      iterLoader = iter(train_loader)\n","      iterHighLoader = iter(train_h_loader)\n","\n","      lossList= list()\n","      for xx in range(len(iterLoader)):\n","          image_batch, _ = next(iterLoader)\n","          image_batch = image_batch.to(device)\n","          \n","          image_batch_recon = model(image_batch)\n","\n","          # Se compara con la imagen de alta definicion\n","          image_h_batch, _ = next(iterHighLoader)\n","          image_h_batch = image_h_batch.to(device)\n","\n","          loss = loss_fn(image_batch_recon, image_h_batch)\n","          #loss = loss_fn(image_batch_recon, image_batch)\n","\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()          \n","          lossList.append(loss.item())\n","\n","      #train_loss_avg[-1] /= num_batches\n","      train_loss_avg.append(np.mean(lossList))\n","\n","      print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, Epochs, train_loss_avg[-1]))\n","    return train_loss_avg, valid_loss_avg\n","    #return train_loss_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"TViDJlP-HJR1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1 / 60] average reconstruction error: 0.071464\n","Epoch [2 / 60] average reconstruction error: 0.012786\n","Epoch [3 / 60] average reconstruction error: 0.007828\n","Epoch [4 / 60] average reconstruction error: 0.006269\n","Epoch [5 / 60] average reconstruction error: 0.005270\n","Epoch [6 / 60] average reconstruction error: 0.004305\n","Epoch [7 / 60] average reconstruction error: 0.003797\n","Epoch [8 / 60] average reconstruction error: 0.003456\n","Epoch [9 / 60] average reconstruction error: 0.003213\n","Epoch [10 / 60] average reconstruction error: 0.002976\n","Epoch [11 / 60] average reconstruction error: 0.002908\n","Epoch [12 / 60] average reconstruction error: 0.002937\n","Epoch [13 / 60] average reconstruction error: 0.003047\n","Epoch [14 / 60] average reconstruction error: 0.002625\n","Epoch [15 / 60] average reconstruction error: 0.002450\n","Epoch [16 / 60] average reconstruction error: 0.002343\n","Epoch [17 / 60] average reconstruction error: 0.002577\n","Epoch [18 / 60] average reconstruction error: 0.002788\n","Epoch [19 / 60] average reconstruction error: 0.002406\n","Epoch [20 / 60] average reconstruction error: 0.002258\n","Epoch [21 / 60] average reconstruction error: 0.002139\n","Epoch [22 / 60] average reconstruction error: 0.002082\n","Epoch [23 / 60] average reconstruction error: 0.002041\n","Epoch [24 / 60] average reconstruction error: 0.001955\n","Epoch [25 / 60] average reconstruction error: 0.002056\n","Epoch [26 / 60] average reconstruction error: 0.002086\n","Epoch [27 / 60] average reconstruction error: 0.002468\n","Epoch [28 / 60] average reconstruction error: 0.002223\n","Epoch [29 / 60] average reconstruction error: 0.002002\n","Epoch [30 / 60] average reconstruction error: 0.001921\n","Epoch [31 / 60] average reconstruction error: 0.001942\n","Epoch [32 / 60] average reconstruction error: 0.001861\n","Epoch [33 / 60] average reconstruction error: 0.001869\n","Epoch [34 / 60] average reconstruction error: 0.001797\n","Epoch [35 / 60] average reconstruction error: 0.001784\n","Epoch [36 / 60] average reconstruction error: 0.001743\n","Epoch [37 / 60] average reconstruction error: 0.001743\n","Epoch [38 / 60] average reconstruction error: 0.001685\n","Epoch [39 / 60] average reconstruction error: 0.001657\n","Epoch [40 / 60] average reconstruction error: 0.001640\n","Epoch [41 / 60] average reconstruction error: 0.001634\n","Epoch [42 / 60] average reconstruction error: 0.001694\n","Epoch [43 / 60] average reconstruction error: 0.001928\n","Epoch [44 / 60] average reconstruction error: 0.001710\n","Epoch [45 / 60] average reconstruction error: 0.001758\n","Epoch [46 / 60] average reconstruction error: 0.001675\n","Epoch [47 / 60] average reconstruction error: 0.001610\n","Epoch [48 / 60] average reconstruction error: 0.001593\n","Epoch [49 / 60] average reconstruction error: 0.001561\n","Epoch [50 / 60] average reconstruction error: 0.001549\n","Epoch [51 / 60] average reconstruction error: 0.001550\n","Epoch [52 / 60] average reconstruction error: 0.001605\n","Epoch [53 / 60] average reconstruction error: 0.001804\n","Epoch [54 / 60] average reconstruction error: 0.001596\n","Epoch [55 / 60] average reconstruction error: 0.001544\n","Epoch [56 / 60] average reconstruction error: 0.001514\n","Epoch [57 / 60] average reconstruction error: 0.001502\n","Epoch [58 / 60] average reconstruction error: 0.001506\n","Epoch [59 / 60] average reconstruction error: 0.001579\n","Epoch [60 / 60] average reconstruction error: 0.001831\n"]}],"source":["learning_rate = 0.0015\n","autoencoder = Autoencoder()\n","autoencoder.to(device)\n","loss = nn.MSELoss()\n","optimizer = torch.optim.Adam(params=autoencoder.parameters(), lr=learning_rate, weight_decay=1e-5)\n","\n","autoencoder.train()\n","\n","\n","loss_result, lossVal = train(autoencoder,train_loader,60,loss, train_h_loader, valid_loader, valid_h_loader)\n","#loss_result, lossVal = train(autoencoder,train_loader,10,loss, train_h_loader, valid_loader, valid_h_loader)\n","\n","\n","# loss_result, lossVal = train(autoencoder,valid_loader, 60, loss, valid_h_loader, test_loader, test_h_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":466,"status":"ok","timestamp":1639455316105,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"v4do5lwRMRVz","outputId":"b03a0cf4-ff04-4493-9786-0af0a08a13dd"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU9Z3H/9cnkxvhIuEqEEIiIkoUAkQEqgLewFrRn9oWVlvs1rq9UOu221V+3cqvdPdR29rWldUqW7HWVbHaarGLWkQQ3YJcFFAQCnINWMGIIAghl8/vjzkzzCRDGCCTyeX9fDzmwZzbzOckw7xzzvec79fcHRERkboy0l2AiIg0TwoIERFJSAEhIiIJKSBERCQhBYSIiCSUme4CGku3bt28qKgo3WWIiLQoK1eu/NDduyda1moCoqioiBUrVqS7DBGRFsXMth1rmU4xiYhIQgoIERFJSAEhIiIJtZo2CJG2rqqqivLycg4fPpzuUqQZys3NpaCggKysrKS3UUCItBLl5eV07NiRoqIizCzd5Ugz4u5UVFRQXl5OcXFx0tvpFJNIK3H48GG6du2qcJB6zIyuXbue8NFlSgPCzCaY2QYz22RmdyZY/nUze9vMVpnZ62Y2KGbZtGC7DWY2PpV1irQWCgc5lpP5bKQsIMwsBNwPXAkMAibHBkDgCXc/z91LgZ8Bvwy2HQRMAkqACcADwes1ugMHDjB9+nTeeOONVLy8iEiLlcojiBHAJnff7O5HgDnANbEruPv+mMn2QGRwimuAOe5e6e5bgE3B6zW6w4cPM2PGDJYtW5aKlxdpU0KhEKWlpdHH3XffnbL3Gjt2LAMHDoy+1w033NDg+lu3buWJJ55IWT0nateuXcetuSH33nsvn376aSNWVF8qG6n7ADtipsuBC+quZGbfAr4LZAOXxGy7tM62fRJseytwK0BhYeFJFZmTkwNAZWXlSW0vIke1a9eOVatWNbhOTU0NoVDomNPJbgfw+OOPU1ZWllRtkYD4h3/4h3rLqqurycxs2mt2evfuzTPPPHPS2997773cdNNN5OXlNWJV8dLeSO3u97t7f+AO4N9OcNtZ7l7m7mXduyfsSuS4FBAiqVdUVMQdd9zBsGHDePrpp+tNP/nkk5x33nmce+653HHHHdHtOnTowPe+9z2GDBnCkiVLknqvm2++mdtuu43Ro0dzxhlnRL+E77zzTl577TVKS0v51a9+xW9/+1smTpzIJZdcwqWXXsrBgwf5x3/8R0aMGMHQoUP505/+BMBvf/tbrrvuOiZMmMCAAQP413/91+h7feMb36CsrIySkhKmT58et7/Tpk2jtLSUsrIy3nzzTcaPH0///v158MEHgXBgnXvuuUA4/L7//e9z/vnnM3jwYB566CEAFi1axNixY7nhhhs4++yzufHGG3F37rvvPnbt2sW4ceMYN24cwDF/hqfE3VPyAEYBL8VMTwOmNbB+BrAv0brAS8Coht5v+PDhfjJqa2sd8B/+8Icntb1Ic7Fu3bq46TFjxtR73H///e7ufvDgwYTLH3nkEXd337NnT71lycjIyPAhQ4ZEH3PmzHF39379+vlPf/rT6Hqx0zt37vS+ffv67t27vaqqyseNG+fPPvusu7sD/tRTTyV8rzFjxvhZZ50Vfa9/+Zd/cXf3KVOm+A033OA1NTW+du1a79+/v7u7L1y40K+66qro9o888oj36dPHKyoq3N192rRp/thjj7m7+969e33AgAF+4MABf+SRR7y4uNg//vhjP3TokBcWFvr27dvd3aPbVldX+5gxY3z16tXR/XvggQfc3f3222/38847z/fv3++7d+/2Hj16uLv7li1bvKSkxN3dH3roIf/xj3/s7u6HDx/24cOH++bNm33hwoXeqVMn37Fjh9fU1PjIkSP9tddei77Hnj17jvszjFX3MxL8jFf4Mb5XU3lMtRwYYGbFwE7Cjc5xx3ZmNsDdNwaTVwGR53OBJ8zsl0BvYACQkkYCMyMnJ0dHECKNoKFTTF/84hcTTi9fvpyxY8cSOQtw4403snjxYq699lpCoRDXX3/9Md/vWKeYrr32WjIyMhg0aBAffPDBMbe//PLL6dKlCwB/+ctfmDt3Lvfccw8Qbp/cvn07AJdeeimnnXYaAIMGDWLbtm307duX3//+98yaNYvq6mref/991q1bx+DBgwGYOHEiAOeddx4HDhygY8eOdOzYkZycHD7++OO4Ov7yl7+wZs2a6NHOvn372LhxI9nZ2YwYMYKCggIASktL2bp1KxdeeGHc9g39DE9FygLC3avNbCrhv/5DwGx3X2tmMwgn1lxgqpldBlQBe4EpwbZrzez3wDqgGviWu9ekqtacnBzdfSqtzqJFi465LC8vr8Hl3bp1a3D5yWjfvn2D04nk5uZG2x3Gjx/PBx98QFlZGb/5zW8a3C5y6hiInIU4bk3uzh/+8AcGDhwYt84bb7wR93qhUIjq6mq2bNnCPffcw/Lly8nPz+fmm2+O+x6JbJORkRG3fUZGBtXV1XHv4e7MnDmT8ePjr+hftGhRwvduKiltg3D3ee5+lrv3d/f/CObdFYQD7v4ddy9x91J3H+fua2O2/Y9gu4Hu/kIq69QRhEj6jBgxgldffZUPP/yQmpoannzyScaMGVNvvZdeeolVq1YdNxyOpWPHjnzyySfHXD5+/HhmzpwZDZS33nqrwdfbv38/7du357TTTuODDz7ghRdO/mtq/Pjx/PrXv6aqqgqAv/3tbxw8eLDBbWL3J9mf4YlSVxsoIEQay6FDhygtLY1OT5gw4biXuvbq1Yu7776bcePG4e5cddVVXHPNNQ1uE3HjjTfSrl07IHzU8/LLLx9z3cGDBxMKhRgyZAg333wz+fn5cct/+MMfcvvttzN48GBqa2spLi7mz3/+8zFfb8iQIQwdOpSzzz6bvn378pnPfCapmhO55ZZb2Lp1K8OGDcPd6d69O88991yD29x6661MmDCB3r17s3DhwpP+GTbEGjr8aknKysr8ZAcMOvPMMxkxYkSzukZa5ES9++67nHPOOekuQ5qxRJ8RM1vp7gmvFU77Za7NgY4gRETqU0AQbghTQIiIxFNAoCMIEZFEFBAoIEREElFAoIAQEUlEAYECQkQkEQUECgiRxtIU3X1v3bqVgoICamtr4+aXlpYec1yX2I7xVqxYwW233ZZwvaKiIj788MMTrmnu3Lkp7do8XXSjHAoIkcbSFN19FxUVUVhYyGuvvRa9W3j9+vV88sknXHBBvREF6ikrK0u6i/BkTZw4Mdr3UmuiIwgUECKp1tjdfU+ePJk5c+ZEp+fMmcOkSZPYunUrF110EcOGDWPYsGH89a9/rVfLokWL+NznPgdARUUFV1xxBSUlJdxyyy1x/TZde+21DB8+nJKSEmbNmhWd/+KLLzJs2DCGDBnCpZdeCoS7BJ86dSoQPlq55JJLGDx4MJdeemm0w79jdUPenOkIAgWEtD633377cf+SP1GlpaXce++9Da5Tt6uNadOmRXtt7dq1K2+++SYQHpshMr1r1y5GjhzJypUryc/P54orruC5557j2muv5eDBg1xwwQX84he/iHufL3zhC5SWljJz5kwyMzN56qmnePrpp+nRowfz588nNzeXjRs3MnnyZBrqYeFHP/oRF154IXfddRf/+7//y8MPPxxdNnv2bLp06cKhQ4c4//zzuf7666mtreVrX/saixcvpri4mI8++qjea377299mypQpTJkyhdmzZ3PbbbdFu814//33ef3111m/fj0TJ048pRHlmoICAgWESGNpqu6+e/bsybnnnsuCBQvo2bMnmZmZnHvuuezbt4+pU6eyatUqQqEQf/vb3xqsd/Hixfzxj38E4Kqrrorrn+m+++7j2WefBWDHjh1s3LiRPXv2cPHFF1NcXAwQ7So81pIlS6Kv+aUvfSlugKFkuyFvLhQQKCCk9TneX/rp0NjdfUdOM/Xs2ZPJkycD8Ktf/YqePXuyevVqamtryc3NPalaFy1axMsvv8ySJUvIy8tj7NixjTIkQLLdkDcXaoMg/Eurqqqqd1WEiKTeyXb3fd111zFv3jyeeuopJk2aBIQH2unVqxcZGRk89thj1NQ0PIzMxRdfHO2k84UXXmDv3r3R18nPzycvL4/169ezdOlSAEaOHMnixYvZsmULQMJTTKNHj462jzz++ONcdNFFJ/NjaRZ0BMHRVD9y5MhJ/8UhIk3b3Xfnzp0ZNWoUf//73znjjDMA+OY3v8n111/P7373OyZMmHDco5Tp06czefJkSkpKGD16NIWFhdG6H3zwQc455xwGDhzIyJEjAejevTuzZs3iuuuuo7a2NtrmEWvmzJl85Stf4ec//zndu3fnkUceOe6+NFfq7hv45S9/yfe+9z327t1L586dG7kykaah7r7leNTd90mIHEGoHUJE5CgFBAoIEZFEFBAoIKT1aC2njKXxncxnQwEB0YZpBYS0ZLm5uVRUVCgkpB53p6Ki4oQvwtFVTOgIQlqHgoICysvL2bNnT7pLkWYoNzeXgoKCE9pGAYECQlqHrKys6B2+Io1Bp5hQQIiIJJLSgDCzCWa2wcw2mdmdCZZ/18zWmdkaM1tgZv1iltWY2argMTeVdSogRETqS9kpJjMLAfcDlwPlwHIzm+vu62JWewsoc/dPzewbwM+ASI9eh9y9lCaggBARqS+VRxAjgE3uvtndjwBzgLj75919obt/GkwuBU6sBaWRKCBEROpLZUD0AXbETJcH847lq8ALMdO5ZrbCzJaa2bWJNjCzW4N1VpzKlRsKCBGR+prFVUxmdhNQBsR24djP3Xea2RnAK2b2tru/F7udu88CZkG4L6aTfX8FhIhIfak8gtgJ9I2ZLgjmxTGzy4AfABPdPfoN7e47g383A4uAoakqVAEhIlJfKgNiOTDAzIrNLBuYBMRdjWRmQ4GHCIfD7pj5+WaWEzzvBnwGiG3cblQKCBGR+lJ2isndq81sKvASEAJmu/taM5sBrHD3ucDPgQ7A02YGsN3dJwLnAA+ZWS3hELu7ztVPjUoBISJSX0rbINx9HjCvzry7Yp5fdozt/gqcl8raYmVnZwMKCBGRWLqTGsjIyCArK6tRxpwVEWktFBCBnJwcHUGIiMRQQAQUECIi8RQQAQWEiEg8BUQgNzdXASEiEkMBEdARhIhIPAVEQAEhIhJPARFQQIiIxFNABBQQIiLxFBABBYSISLwGA8LMQma2sKmKSScFhIhIvAYDwt1rgFozO62J6kkbBYSISLxkOus7ALxtZvOBg5GZ7n5byqpKAwWEiEi8ZALij8GjVVNAiIjEO25AuPujwYA/ZwWzNrh7VWrLanoKCBGReMcNCDMbCzwKbAUM6GtmU9x9cWpLa1oKCBGReMmcYvoFcIW7bwAws7OAJ4HhqSysqSkgRETiJXMfRFYkHADc/W9AVupKSo9IQLh7uksREWkWkjmCWGlmvwH+J5i+EViRupLSIzIu9ZEjR6LPRUTasmQC4uvAt4DIZa2vAQ+krKI0iYRCZWWlAkJEhOMEhJmFgNXufjbwy6YpKT1iA0JERJK7k3qDmRU2UT1po4AQEYmXzCmmfGCtmS0j/k7qiSmrKg1yc3MBBYSISEQyAfHDlFfRDOgIQkQk3nF7cwUecvdX6z6SeXEzm2BmG8xsk5ndmWD5d81snZmtMbMFZtYvZtkUM9sYPKac8J6dIAWEiEi8lLVBBOFyP3AlMAiYbGaD6qz2FlDm7oOBZ4CfBdt2AaYDFwAjgOlmln+iNZwIBYSISLxUtkGMADa5+2YAM5sDXAOsi3mN2LEmlgI3Bc/HA/Pd/aNg2/nABMJ3cKeEAkJEJF4q2yD6ADtipssJHxEcy1eBFxrYtk/dDczsVuBWgMLCU7vQSgEhIhIvmd5cXw3aBga4+8tmlgeEGrMIM7sJKAPGnMh27j4LmAVQVlZ2Sn1kKCBEROIdty8mM/sa4faBh4JZfYDnknjtnUDfmOmCYF7d178M+AEw0d0rT2TbxqSAEBGJl0xnfd8CPgPsB3D3jUCPJLZbDgwws+JgPIlJwNzYFcxsKOHgmejuu2MWvQRcYWb5QeP0FcG8lFFAiIjES6YNotLdj5gZAGaWCRz3dI67V5vZVMJf7CFgtruvNbMZwAp3nwv8HOgAPB28/nZ3n+juH5nZjwmHDMCMSIN1qiggRETiJRMQr5rZ/wu0M7PLgW8Czyfz4u4+D5hXZ95dMc8va2Db2cDsZN6nMSggRETiJXOK6U5gD/A28E+Ev/D/LZVFpYMCQkQkXjJXMdUC/x08Wq1IQBw+fDjNlYiINA/JHEG0CTqCEBGJp4AIhEIhQqGQAkJEJKCAiBEZl1pERJJogzCzs4DvA/1i13f3S1JYV1ooIEREjkrmMtengQcJN1LXpLac9MrNzVVAiIgEkgmIanf/dcoraQZ0BCEiclQybRDPm9k3zayXmXWJPFJeWRooIEREjkrmCCIymtv3Y+Y5cEbjl5NeCggRkaOSuVGuuCkKaQ4UECIiRyVzFVMW8A3g4mDWIsLjVFelsK60UECIiByVzCmmXwNZwAPB9JeCebekqqh0ycnJ4dChQ+kuQ0SkWUgmIM539yEx06+Y2epUFZROOTk5fPzxx+kuQ0SkWUjmKqYaM+sfmTCzM2il90PoFJOIyFHJHEF8H1hoZpsBI3xH9VdSWlWaKCBERI5K5iqmBWY2ABgYzNoQM3Z0q6KAEBE56pgBYWaXuPsrZnZdnUVnmhnu/scU19bkFBAiIkc1dAQxBngFuDrBMgcUECIirdgxA8LdpwdPZ7j7lthlZtYqb57LycnRiHIiIoFkrmL6Q4J5zzR2Ic1B5AjC3dNdiohI2jXUBnE2UAKcVqcdohOQm+rC0iEnJwd3p7q6mqysrHSXIyKSVg21QQwEPgd0Jr4d4hPga6ksKl1ix6VWQIhIW9dQG8SfgD+Z2Sh3X9KENaVNbm74wKiyspIOHTqkuRoRkfRKpg3i62bWOTJhZvlmNjuZFzezCWa2wcw2mdmdCZZfbGZvmlm1md1QZ1mNma0KHnOTeb9TFXsEISLS1iVzJ/Vgd492UOTue81s6PE2MrMQcD9wOVAOLDezue6+Lma17cDNwL8keIlD7l6aRH2NRgEhInJUMkcQGWaWH5kIRpNLJlhGAJvcfbO7HwHmANfEruDuW919DVB7AjWnjAJCROSoZL7ofwEsMbOnCffFdAPwH0ls1wfYETNdDlxwArXlmtkKoBq4292fq7uCmd0K3ApQWFh4Ai+dmAJCROSoZPpi+l3wRX1JMOu6OqeJUqWfu+8Meo99xczedvf36tQ2C5gFUFZWdso3LyggRESOSmZEuULgADA3dp67bz/OpjuBvjHTBcG8pLj7zuDfzWa2CBgKvNfgRqdIASEiclQyp5j+l3DfSwDtgGJgA+Gb6BqyHBgQdMuxE5gE/EMyRQVtHp+6e6WZdQM+A/wsmW1PhQJCROSoZE4xnRc7bWbDgG8msV21mU0FXgJCwGx3X2tmM4AV7j7XzM4HngXygavN7EfuXgKcAzxkZrWEG9LvborTWgoIEZGjkjmCiOPub5pZUo3N7j4PmFdn3l0xz5cTPvVUd7u/AufVnZ9qCggRkaOSaYP4bsxkBjAM2JWyitJIASEiclQyRxAdY55XE26TSNTDa4ungBAROarBgAjuhu7o7onudG51FBAiIkc1eCe1u9cQvoKoTYgEhAYNEhFJ7hRTpLO8p4GDkZmtdUxq0BGEiAgkFxC5QAVH76SGVjwmNSggREQguYD4jbv/X+wMM2uVp50yMzMxMwWEiAjJ9eY6M8l5LZ6ZRcelFhFp6xoak3oUMBroXudeiE6E74xulXJzcxUQIiI0fIopG+gQrBN7L8R+wl1+t0o6ghARCWtoTOpXgVfN7Lfuvg3AzDKADu6+v6kKbGoKCBGRsGTaIH5iZp3MrD3wDrDOzL6f4rrSRgEhIhKWTEAMCo4YrgVeINzd95dSWlUaKSBERMKSCYgsM8siHBBz3b2Ko+NDtDoKCBGRsGQC4iFgK9AeWGxm/Qg3VLdKCggRkbBkBgy6D7gvZtY2MxuXupLSSwEhIhKWzHgQOcD1QFGd9WekqKa0ysnJ4cCBA+kuQ0Qk7ZLpauNPwD5gJdDq/7TWEYSISFgyAVHg7hNSXkkzoYAQEQlLppH6r2bW5ONDp4sCQkQkLJkjiAuBm81sC+FTTAa4uw9OaWVpkpOTowGDRERILiCuTHkVzYiOIEREwo57iinoh6kzcHXw6Bzpm6k1UkCIiIQdNyDM7DvA40CP4PE/ZvbtVBeWLgoIEZGwZBqpvwpc4O53uftdwEjga8m8uJlNMLMNZrbJzO5MsPxiM3vTzKrN7IY6y6aY2cbgMSWZ92sMOTk51NTUUFNT01RvKSLSLCUTEAbEflvWBPMa3sgsBNxPuA1jEDDZzAbVWW07cDPwRJ1tuwDTgQuAEcB0M8tPotZTlpubC2hcahGRZBqpHwHeMLNng+lrgYeT2G4EsMndNwOY2RzgGmBdZAV33xosq62z7Xhgvrt/FCyfD0wAnkzifU9JTk4OEA6IvLy8VL+diEizlUxfTL80s0WEL3cF+Iq7v5XEa/cBdsRMlxM+IkhGom371F3JzG4FbgUoLCxM8qUbFhsQIiJtWTJ9MY0E1rr7m8F0JzO7wN3fSHl1x+Hus4BZAGVlZY3SBbkCQkQkLJk2iF8Dsb3XHQjmHc9OoG/MdEEwLxmnsu0pUUCIiIQl1Ujt7tG/zt29luTaLpYDA8ys2MyygUnA3CTregm4wszyg8bpK4J5KaeAEBEJSyYgNpvZbWaWFTy+A2w+3kbuXg1MJfzF/i7we3dfa2YzzGwigJmdb2blwOeBh8xsbbDtR8CPCYfMcmBGpME61RQQIiJhyRwJfJ3wgEH/Rnio0QUEDcPH4+7zgHl15t0V83w54dNHibadDcxO5n0akwJCRCQsmauYdhM+PdQmKCBERMKS6WrjLDNbYGbvBNODzezfUl9aeiggRETCkmmD+G9gGlAF4O5raEVHFIcPH+af/umfmDs33H6ugBARCUsmIPLcfVmdedWpKCYdcnJyePTRR3n99dej06CAEBFJJiA+NLP+hBuoCTrVez+lVTUhM6N3797s3Bm+zSISEBo0SETaumSuYvoW4buVzzazncAW4MaUVtXE+vTpQ3l5OaAjCBGRiGQGDNrs7pcB3YGzgTEc7ZepVSgoKKh3BKGAEJG27pgBEfS5NM3M/svMLgc+BaYAm4AvNFWBTaGoqIjMzPDBlAJCRCSsoSOIx4CBwNuEBwhaSPiO5//H3a9pgtqazE9+8hPWr18PKCBERCIaaoM4w93PAzCz3xBumC5091bdepudnQ0oIEREGjqCqIo8cfcaoLy1hsPmzZu56qqr+L//+z/MTONSi4jQcEAMMbP9weMTYHDkuZntb6oCm0IoFGLevHm8++67AAoIEREaOMXk7qGmLCSdevXqBRB3JZMCQkTaumRulGv1srOz6dmzZ9y9EAoIEWnrFBCBPn366AhCRCRGMndStwnDhw+PhoICQkREARE1a9as6HMFhIiITjElpIAQEVFARM2fP5/BgwezdetWBYSICAqIOG+//Tbbt29XQIiIoICI6tOnDwDl5eUKCBERFBBRBQUFQPhmOQWEiIgCIqpTp0506NAhGhAaUU5E2joFRIyJEyfSr18/HUGIiJDigDCzCWa2wcw2mdmdCZbnmNlTwfI3zKwomF9kZofMbFXweDCVdUY8/vjj/PM//7MCQkSEFN4oZ2Yh4H7gcqAcWG5mc919XcxqXwX2uvuZZjYJ+CnwxWDZe+5emqr6GqKAEBFJ7RHECGBTMKb1EWAOUHckumuAR4PnzwCXmpmlsKYG3XvvvfTo0YPs7GwFhIi0eakMiD7Ajpjp8mBewnXcvRrYB3QNlhWb2Vtm9qqZXZToDczsVjNbYWYr9uzZc8oFZ2VlsWfPHmpqaqiqqqK2tvaUX1NEpKVqro3UkeFNhwLfBZ4ws051V3L3We5e5u5l3bt3P+U3jVzqGrmC6ciRI6f8miIiLVUqA2In0DdmuiCYl3AdM8sETgMq3L3S3SsA3H0l8B5wVgprBY7eLHfo0CFA41KLSNuWyoBYDgwws2IzywYmAXPrrDMXmBI8vwF4xd3dzLoHjdyY2RnAAGBzCmsFjgbEgQMHAAWEiLRtKbuKyd2rzWwq8BIQAma7+1ozmwGscPe5wMPAY2a2CfiIcIgAXAzMMLMqoBb4urt/lKpaI3r06MHkyZOJnK5SQIhIW5bS8SDcfR4wr868u2KeHwY+n2C7PwB/SGVtiYRCIZ544gkee+wxQAEhIm1bc22kTqtQKAQoIESkbdOIcnV8+ctfZuHChYACQkTaNh1B1JGfn09FRQWggBCRtk0BUUdBQYEucxURQQFRT+RSV1BAiEjbpoCoQwEhIhKmgKjjrLPOYsqU8L17GjRIRNoyBUQdvXr14gc/+AGgIwgRadsUEAlUV1cDCggRadsUEAlcd911gAJCRNo2BUQCkYZqBYSItGUKiAQi40IoIESkLVNAJFBYWAjAp59+muZKRETSRwGRQN++4XGOPvoo5T2Mi4g0WwqIBC666CJycnKoqalJdykiImmjgEjg7LPPZuDAgTz88MNMnTqVDz74IN0liYg0OQVEAu7OzJkzmTRpEg8++CD9+/dn+vTpfPLJJ+kuTUSkySggjmH8+PHs3r2bpUuX8tnPfpYZM2bQv39/Hn74Ydw93eWJiKScAiIBM+Ouu+7i5Zdf5uqrr+YLX/gCb7zxBueccw633HILN910EwcOHEh3mSIiKaWAOIZp06axbNkyevXqxec//3nuueceXnnlFf793/+dOXPmcP755/POO++ku0wRkZRRQDRg+PDhLFu2jHvuuYcLLriAUCjEd7/7XR544AH27t3LiBEjePTRR9NdpohISlhrOZ9eVlbmK1asSPn7PP/880ycOJHTTz+djIwMdu3axec+9zmuvvpqRo8ezaBBg8jIUO6KSMtgZivdvSzhMgXEiamoqOD555/n+eef58UXX6x3t3XHjh0555xzGDNmDCWIQA4AAAylSURBVCUlJZxxxhkUFxfTu3dvBYeINDsKiBSprKxk0aJFvPbaa3z5y19m6dKl/OQnP2H9+vX11s3OzqawsJCsrCyysrLo2rUrPXr0oGfPnnTr1o2SkhLat29PTU0NeXl5dOjQgQ4dOkSf5+XlEQqFqK2tpbq6OvoIhULk5uaSlZVFKBRq0v0XkZYvbQFhZhOA/wRCwG/c/e46y3OA3wHDgQrgi+6+NVg2DfgqUAPc5u4vNfRe6QiIRHbv3s3KlStZs2YNGzZsYPPmzezbt4/x48ezbds2Xn75ZT788MOUvHfsEYqZEQqFyMjIoEOHDvTt2xczY/v27dTU1GBmmBkA7du3p3v37tTW1rJt27Z62+fn59OnTx8yMzPZtGkTGRkZhEIhQqEQmZmZ9OzZk379+pGRkcG6devIyMiIPkKhEL1796agoIDa2lrWr18f3S4Sln379qV3795UV1ezZcuWuG1DoRC9evWia9euHD58mB07dpCRkRGt38w4/fTTOe200/j000/ZtWtX3DIzo3fv3rRv356DBw+ya9eu6M8qtv68vDyOHDnCgQMHyM7OJisri8zMTEKhEJ06dSInJ4fKyko+/fRTzCzuUuf8/HwyMzPZt28fH330EVVVVdEANzMKCgrIyMhg3759HDx4kJycHHJzc8nNzSUnJ4f8/Pxo+NfW1sbte+R3EHnE7lfk95RoXqJ/664fO53oeew20no1FBCZKXzTEHA/cDlQDiw3s7nuvi5mta8Ce939TDObBPwU+KKZDQImASVAb+BlMzvL3Zt93xc9evTgyiuv5Morr0y4/MiRI3zyySfs37+fiooKduzYweHDhykpKeHgwYPMnz+fbdu2cfjwYY4cOUJlZSW5ubkMHTqU2tpaVqxYwYEDB6JfGLW1tbRv357S0lKqqqp48cUX+fjjj6NfUlVVVXTu3Jk+ffrg7mzbto0jR47g7rg7ZkaHDh04/fTTMTPee+89qqurqa2txd2pra0lFAqRn59PdXU17733Xr37QDp06MDq1as5cuRIwv6r6n6hSusSCZBEv2Mzi/7hkqjrmkhIA9HPZazMzMzo8rpDAJtZ9A8NgEOHDtV7/ezsbLKzswESXpoe+UOgtrY24RDDoVAo+vk9Vv2RI/eqqqp6y/Py8sjMzKSmpiZ6Ojo2cDt16kRmZmb0j5O6OnfuTCgU4tChQ/WWuzu5ubnU1tZy/vnn8/rrr9fb/lSlLCCAEcAmd98MYGZzgGuA2IC4Bvj/gufPAP9l4Z/eNcAcd68EtpjZpuD1lqSw3iaRnZ1N165d6dq1K8XFxZSVxQf3qFGjTun1f/zjH5/S9smKhEfkaCQrKwt3Z+/evdFlkUf79u3p1KkTR44cYfPmzVRVVUXDr7Kykm7dupGfn8+BAwdYvXo1NTU11NTURE+n9evXjx49erB//35Wr14dDa/Il8mAAQPo0aMHe/fuZc2aNdFlkTpKSkro1q0bFRUVrFu3Lq726upqSktLyc/PZ8eOHbz11ltxp/DcnVGjRtGpUye2b98ed2lz5C/uUaNGkZeXx65du9i6dWv0Sy/yRTBq1CjatWvH5s2b2bhxI1VVVdGfQVVVFePGjSMjI4O1a9dGAzi2/iuvvBJ3Z9WqVWzbti1u30OhEOPHj8fdeeuttygvL4/+fgBycnK47LLLAFi2bBm7d++O275du3aMHTsWd2fJkiVUVFTEfUl36tSJCy+8EHfn9ddfZ9++fXGfgy5dujBy5EjcnVdffZWDBw/Gbd+jRw/KyspwdxYsWEBlZWV0ubvTq1cvSktLAZg/f370Zx7Rt29fzj33XABeeOGFuJ+9u1NUVMTAgQOprq5m/vz5cdu6O/379+fMM8+ksrKSxYsXR7eN/HvWWWdRVFTE4cOHWbKk/tfLoEGDKCwsZP/+/axYsSL6O48ERklJCT169GDPnj0sXbo0+r6Rx7Bhw+jevTsffPABK1eurBeAZWVldOnShffff5+33347bpm7M3LkSDp16sSuXbvYtGlTNHAjdYwePZpOnTrRr1+/erU3hpSdYjKzG4AJ7n5LMP0l4AJ3nxqzzjvBOuXB9HvABYRDY6m7/08w/2HgBXd/ps573ArcClBYWDg8cnpERESS09ApphZ9WY27z3L3Mncv6969e7rLERFpVVIZEDuBvjHTBcG8hOuYWSZwGuHG6mS2FRGRFEplQCwHBphZsZllE250nltnnbnAlOD5DcArHj7nNReYZGY5ZlYMDACWpbBWERGpI2WN1O5ebWZTgZcIX+Y6293XmtkMYIW7zwUeBh4LGqE/IhwiBOv9nnCDdjXwrZZwBZOISGuiG+VERNqwVttILSIiqaOAEBGRhBQQIiKSUKtpgzCzPcCp3CnXDUhNJ0lNrzXtC7Su/WlN+wLan+Ys2X3p5+4JbyRrNQFxqsxsxbEaalqa1rQv0Lr2pzXtC2h/mrPG2BedYhIRkYQUECIikpAC4qhZ6S6gEbWmfYHWtT+taV9A+9OcnfK+qA1CREQS0hGEiIgkpIAQEZGE2nxAmNkEM9tgZpvM7M5013OizGy2me0OBl+KzOtiZvPNbGPwb346a0yWmfU1s4Vmts7M1prZd4L5LXV/cs1smZmtDvbnR8H8YjN7I/jMPRX0dtwimFnIzN4ysz8H0y15X7aa2dtmtsrMVgTzWuRnDcDMOpvZM2a23szeNbNRp7o/bTogYsbNvhIYBEwOxsNuSX4LTKgz705ggbsPABYE0y1BNfA9dx8EjAS+Ffw+Wur+VAKXuPsQoBSYYGYjCY+9/it3PxPYS3hs9pbiO8C7MdMteV8Axrl7acz9Ai31swbwn8CL7n42MITw7+nU9id2/NS29gBGAS/FTE8DpqW7rpPYjyLgnZjpDUCv4HkvYEO6azzJ/foTcHlr2B8gD3iT8JC6HwKZwfy4z2BzfhAeuGsBcAnwZ8Ba6r4E9W4FutWZ1yI/a4QHW9tCcOFRY+1Pmz6CAPoAO2Kmy4N5LV1Pd38/eP53oGc6izkZZlYEDAXeoAXvT3BKZhWwG5gPvAd87O7VwSot6TN3L/CvQG0w3ZWWuy8ADvzFzFYG49tDy/2sFQN7gEeCU4C/MbP2nOL+tPWAaPU8/KdDi7qW2cw6AH8Abnf3/bHLWtr+uHuNu5cS/ut7BHB2mks6KWb2OWC3u69Mdy2N6EJ3H0b4FPO3zOzi2IUt7LOWCQwDfu3uQ4GD1DmddDL709YDorWOff2BmfUCCP7dneZ6kmZmWYTD4XF3/2Mwu8XuT4S7fwwsJHwapnMwBju0nM/cZ4CJZrYVmEP4NNN/0jL3BQB33xn8uxt4lnCAt9TPWjlQ7u5vBNPPEA6MU9qfth4QyYyb3RLFjvU9hfC5/GbPzIzwMLTvuvsvYxa11P3pbmadg+ftCLenvEs4KG4IVmsR++Pu09y9wN2LCP8/ecXdb6QF7guAmbU3s46R58AVwDu00M+au/8d2GFmA4NZlxIesvnU9ifdjSvpfgCfBf5G+NzwD9Jdz0nU/yTwPlBF+K+IrxI+N7wA2Ai8DHRJd51J7suFhA+B1wCrgsdnW/D+DAbeCvbnHeCuYP4ZwDJgE/A0kJPuWk9wv8YCf27J+xLUvTp4rI3832+pn7Wg9lJgRfB5ew7IP9X9UVcbIiKSUFs/xSQiIseggBARkYQUECIikpACQkREElJAiIhIQgoIkeMws5qgx8/Io9E6cDOzotieeEWak8zjryLS5h3ycHcZIm2KjiBETlIwnsDPgjEFlpnZmcH8IjN7xczWmNkCMysM5vc0s2eD8SFWm9no4KVCZvbfwZgRfwnuusbMbgvGxlhjZnPStJvShikgRI6vXZ1TTF+MWbbP3c8D/otwb6cAM4FH3X0w8DhwXzD/PuBVD48PMYzwHbwAA4D73b0E+Bi4Pph/JzA0eJ2vp2rnRI5Fd1KLHIeZHXD3DgnmbyU8INDmoJPBv7t7VzP7kHAf/FXB/PfdvZuZ7QEK3L0y5jWKgPkeHtAFM7sDyHL3fzezF4EDhLtNeM7dD6R4V0Xi6AhC5NT4MZ6fiMqY5zUcbRu8ivCIh8OA5TG9poo0CQWEyKn5Ysy/S4LnfyXc4ynAjcBrwfMFwDcgOpDQacd6UTPLAPq6+0LgDsIjhtU7ihFJJf1FInJ87YJR4SJedPfIpa75ZraG8FHA5GDetwmP7PV9wqN8fSWY/x1glpl9lfCRwjcI98SbSAj4nyBEDLjPw2NKiDQZtUGInKSgDaLM3T9Mdy0iqaBTTCIikpCOIEREJCEdQYiISEIKCBERSUgBISIiCSkgREQkIQWEiIgk9P8DLpjwNid7c1AAAAAASUVORK5CYII=\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["fig = plt.figure()\n","plt.plot(loss_result,'k--', label='Error-Entrenamiento')\n","plt.plot(lossVal,'k', label='Error-Validacion')\n","plt.xlabel('Epochs')\n","plt.ylabel('Reconstruction error')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpWs7nRlMcY4"},"outputs":[],"source":["def Show(out, title = ''):\n","  print(title)\n","  out = out.permute(1,0,2,3)\n","  grilla = torchvision.utils.make_grid(out,10,5)\n","  plt.imshow(transforms.ToPILImage()(grilla), 'jet')\n","  plt.show()\n","\n","def Show_Weight(out):\n","  grilla = torchvision.utils.make_grid(out)\n","  plt.imshow(transform.ToPILImage()(grilla), 'jet')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1DdCyPKLPszzPdGdGMC1WvnuCwolr6c0t"},"executionInfo":{"elapsed":13971,"status":"ok","timestamp":1639455358031,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"iwhwvzMw4S8N","outputId":"6bdb9924-1753-4527-872c-f65225474b1d"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["#Evaluacion de los resultados con el set de TRAIN\n","autoencoder.eval()\n","\n","with torch.no_grad():\n","  image,label = iter(train_loader).next()\n","  image = image.to(device)\n","  z,c = autoencoder.encoder(image)\n","\n","  decodificado = autoencoder.decoder(z,c)\n","  decodificado = decodificado.to('cpu')\n","\n","  fig, ax = plt.subplots(figsize=(25, 25))\n","  Show_Weight(decodificado)\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1FCSRHoQEUvGd03i7HMB2Ocu5XzDvHk_I"},"executionInfo":{"elapsed":13497,"status":"ok","timestamp":1639453746902,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"0jD2XCftMcAu","outputId":"12210899-06e4-4a0c-ad54-23693c74307b"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["#Evaluacion de los resultados con el set de VALIDACION\n","autoencoder.eval()\n","\n","with torch.no_grad():\n","  image,label = iter(valid_loader).next()\n","  image = image.to(device)\n","  z,c = autoencoder.encoder(image)\n","  '''\n","  z = z.to('cpu')\n","  mean = z.mean(dim=0)\n","\n","  std = (z - mean).pow(2).mean(dim=0).sqrt()\n","  \n","  z1 = torch.randn(1000, latent_dims)*std + mean\n","  z1 = z1.to(device)\n","  '''\n","\n","  decodificado = autoencoder.decoder(z,c)\n","  decodificado = decodificado.to('cuda')\n","\n","  fig, ax = plt.subplots(figsize=(25, 25))\n","  Show_Weight(decodificado)\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":981,"output_embedded_package_id":"1S2hcWxPVWdCGSxJnkZ1IcF6t-v4ZGxZr"},"executionInfo":{"elapsed":17091,"status":"ok","timestamp":1639453472902,"user":{"displayName":"Juancarlos Cruz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizwxfJVOuqmfolHxBYmHuaBgmVjmy6Chs-mOgPkg=s64","userId":"01169531857995046774"},"user_tz":300},"id":"jCWPbFyNMf09","outputId":"ce890b63-46cb-4e99-95e3-8ecb5cba1f2c"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["#Evaluacion de los resultados con el set de TEST\n","autoencoder.eval()\n","\n","with torch.no_grad():\n","  image,label = iter(test_loader).next()\n","  image = image.to(device)\n","  z,c = autoencoder.encoder(image)\n","\n","  decodificado = autoencoder.decoder(z,c)\n","  decodificado = decodificado.to('cpu')\n","\n","  fig, ax = plt.subplots(figsize=(25, 25))\n","  Show_Weight(decodificado)\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"6KiiSvzuLHfk","outputId":"ac54cd0c-01ff-40b1-8616-058a2d3c43d4"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nautoencoder.eval()\\n\\n\\ntensor = torch.zeros(len(test_loader),10)\\n\\n\\nwith torch.no_grad():\\n\\n  image,label = iter(test_loader).next()\\n  #image,label = iter(test_loader).next()\\n  image = image.to(device)\\n  z,c = autoencoder.encoder(image)\\n  z = z.to('cpu')\\n  mean = z.mean(dim=0)\\n\\n  std = (z - mean).pow(2).mean(dim=0).sqrt()\\n  \\n  z1 = torch.randn(1000, latent_dims)*std + mean\\n  z1 = z1.to(device)\\n  decodificado = autoencoder.decoder(z1,c)\\n \\n  \\n \\n  decodificado = decodificado.to('cpu')\\n\\n  fig, ax = plt.subplots(figsize=(25, 25))\\n  Show_Weight(decodificado[1:1000])\\n  plt.show()\\n\\n\\n  \""]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","autoencoder.eval()\n","\n","\n","tensor = torch.zeros(len(test_loader),10)\n","\n","\n","with torch.no_grad():\n","\n","  image,label = iter(test_loader).next()\n","  #image,label = iter(test_loader).next()\n","  image = image.to(device)\n","  z,c = autoencoder.encoder(image)\n","  z = z.to('cpu')\n","  mean = z.mean(dim=0)\n","\n","  std = (z - mean).pow(2).mean(dim=0).sqrt()\n","  \n","  z1 = torch.randn(1000, latent_dims)*std + mean\n","  z1 = z1.to(device)\n","  decodificado = autoencoder.decoder(z1,c)\n"," \n","  \n"," \n","  decodificado = decodificado.to('cpu')\n","\n","  fig, ax = plt.subplots(figsize=(25, 25))\n","  Show_Weight(decodificado[1:1000])\n","  plt.show()\n","\n","\n","  '''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q7fUukPWMZ1g"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CNN_Autoencoder_Proy4_Opt_capa4.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}